{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "916175c5-ba8c-46c6-91e7-c404d0b1f477",
   "metadata": {},
   "source": [
    "In this exercise, you'll practice using BeautifulSoup to parse the content of a web page. The page that you'll be scraping, https://realpython.github.io/fake-jobs/, contains job listings. Your job is to extract the data on each job and convert into a pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a815b4c-3f6b-40dc-aab7-a0c27fb236a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599d609a-f17b-4a3c-bc54-d4e7b0028675",
   "metadata": {},
   "source": [
    "1. Start by performing a GET request on the url above and convert the response into a BeautifulSoup object.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "776b43f5-7a0d-4ced-aac2-b12c3648453a",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://realpython.github.io/fake-jobs/\"\n",
    "response = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0d895bd4-ea47-4f39-9c85-13499d75a97e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4bfecfb1-b183-4cc0-8b82-75f7e3eda269",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5bb0b141-d59e-4790-8ff8-2102cfa2d0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(soup.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ff09a9-9bc3-43fb-bc5a-8dd2bbcf57cf",
   "metadata": {},
   "source": [
    "a. Use the .find method to find the tag containing the first job title (\"Senior Python Developer\"). Hint: can you find a tag type and/or a class that could be helpful for extracting this information? Extract the text from this title.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dcad72b9-07bf-4c6d-9de6-c5d292855a04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<h2 class=\"title is-5\">Senior Python Developer</h2>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('h2', 'title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "adc22530-6fbf-41f0-9007-36b9d6a78014",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.element.Tag"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(soup.find('h2', 'title'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a5621faa-c81f-40eb-a231-b269e712ba02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Senior Python Developer'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('h2', 'title').text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219bbea6-798d-4fcf-97f3-07cea76ce824",
   "metadata": {},
   "source": [
    "b. Now, use what you did for the first title, but extract the job title for all jobs on this page. Store the results in a list.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8a060830-238b-4246-81e1-39b3c2719f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title_tags = soup.find_all('h2','title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c90f3b8e-b374-4bcc-9e15-4649ade7eb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_titles = [tag.text.strip() for tag in job_title_tags]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2d7a91b6-b630-4ef5-8b52-6f29b394c332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# job_titles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af3cf69-be35-4c7f-9960-a80f9766a646",
   "metadata": {},
   "source": [
    "c. Finally, extract the companies, locations, and posting dates for each job. For example, the first job has a company of \"Payne, Roberts and Davis\", a location of \"Stewartbury, AA\", and a posting date of \"2021-04-08\". Ensure that the text that you extract is clean, meaning no extra spaces or other characters at the beginning or end.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1586c14a-46d6-4d85-ac68-888484fc5d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_cards = soup.find_all('div', 'card-content')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ce291e27-5aca-4d84-ab2e-283c11484498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# job_cards "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "47454956-f417-4209-b29d-8aaa12b6bfea",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = []\n",
    "companies = []\n",
    "locations = []\n",
    "posting_dates = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "22305b7b-8163-431e-9e95-68d9d978001f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for card in job_cards:\n",
    "    title = card.find('h2', class_='title').text.strip()\n",
    "    company = card.find('h3', class_='company').text.strip()\n",
    "    location = card.find('p', class_='location').text.strip()\n",
    "    date = card.find('time')['datetime'].strip()\n",
    "    \n",
    "    titles.append(title)\n",
    "    companies.append(company)\n",
    "    locations.append(location)\n",
    "    posting_dates.append(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "27f48c45-73c6-4777-8b0a-9d8e877d2243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Senior Python Developer | Payne, Roberts and Davis | Stewartbury, AA | 2021-04-08\n",
      "Energy engineer | Vasquez-Davidson | Christopherville, AA | 2021-04-08\n",
      "Legal executive | Jackson, Chambers and Levy | Port Ericaburgh, AA | 2021-04-08\n",
      "Fitness centre manager | Savage-Bradley | East Seanview, AP | 2021-04-08\n",
      "Product manager | Ramirez Inc | North Jamieview, AP | 2021-04-08\n",
      "Medical technical officer | Rogers-Yates | Davidville, AP | 2021-04-08\n",
      "Physiological scientist | Kramer-Klein | South Christopher, AE | 2021-04-08\n",
      "Textile designer | Meyers-Johnson | Port Jonathan, AE | 2021-04-08\n",
      "Television floor manager | Hughes-Williams | Osbornetown, AE | 2021-04-08\n",
      "Waste management officer | Jones, Williams and Villa | Scotttown, AP | 2021-04-08\n",
      "Software Engineer (Python) | Garcia PLC | Ericberg, AE | 2021-04-08\n",
      "Interpreter | Gregory and Sons | Ramireztown, AE | 2021-04-08\n",
      "Architect | Clark, Garcia and Sosa | Figueroaview, AA | 2021-04-08\n",
      "Meteorologist | Bush PLC | Kelseystad, AA | 2021-04-08\n",
      "Audiological scientist | Salazar-Meyers | Williamsburgh, AE | 2021-04-08\n",
      "English as a second language teacher | Parker, Murphy and Brooks | Mitchellburgh, AE | 2021-04-08\n",
      "Surgeon | Cruz-Brown | West Jessicabury, AA | 2021-04-08\n",
      "Equities trader | Macdonald-Ferguson | Maloneshire, AE | 2021-04-08\n",
      "Newspaper journalist | Williams, Peterson and Rojas | Johnsonton, AA | 2021-04-08\n",
      "Materials engineer | Smith and Sons | South Davidtown, AP | 2021-04-08\n",
      "Python Programmer (Entry-Level) | Moss, Duncan and Allen | Port Sara, AE | 2021-04-08\n",
      "Product/process development scientist | Gomez-Carroll | Marktown, AA | 2021-04-08\n",
      "Scientist, research (maths) | Manning, Welch and Herring | Laurenland, AE | 2021-04-08\n",
      "Ecologist | Lee, Gutierrez and Brown | Lauraton, AP | 2021-04-08\n",
      "Materials engineer | Davis, Serrano and Cook | South Tammyberg, AP | 2021-04-08\n",
      "Historic buildings inspector/conservation officer | Smith LLC | North Brandonville, AP | 2021-04-08\n",
      "Data scientist | Thomas Group | Port Robertfurt, AA | 2021-04-08\n",
      "Psychiatrist | Silva-King | Burnettbury, AE | 2021-04-08\n",
      "Structural engineer | Pierce-Long | Herbertside, AA | 2021-04-08\n",
      "Immigration officer | Walker-Simpson | Christopherport, AP | 2021-04-08\n",
      "Python Programmer (Entry-Level) | Cooper and Sons | West Victor, AE | 2021-04-08\n",
      "Neurosurgeon | Donovan, Gonzalez and Figueroa | Port Aaron, AP | 2021-04-08\n",
      "Broadcast engineer | Morgan, Butler and Bennett | Loribury, AA | 2021-04-08\n",
      "Make | Snyder-Lee | Angelastad, AP | 2021-04-08\n",
      "Nurse, adult | Harris PLC | Larrytown, AE | 2021-04-08\n",
      "Air broker | Washington PLC | West Colin, AP | 2021-04-08\n",
      "Editor, film/video | Brown, Price and Campbell | West Stephanie, AP | 2021-04-08\n",
      "Production assistant, radio | Mcgee PLC | Laurentown, AP | 2021-04-08\n",
      "Engineer, communications | Dixon Inc | Wrightberg, AP | 2021-04-08\n",
      "Sales executive | Thompson, Sheppard and Ward | Alberttown, AE | 2021-04-08\n",
      "Software Developer (Python) | Adams-Brewer | Brockburgh, AE | 2021-04-08\n",
      "Futures trader | Schneider-Brady | North Jason, AE | 2021-04-08\n",
      "Tour manager | Gonzales-Frank | Arnoldhaven, AE | 2021-04-08\n",
      "Cytogeneticist | Smith-Wong | Lake Destiny, AP | 2021-04-08\n",
      "Designer, multimedia | Pierce-Herrera | South Timothyburgh, AP | 2021-04-08\n",
      "Trade union research officer | Aguilar, Rivera and Quinn | New Jimmyton, AE | 2021-04-08\n",
      "Chemist, analytical | Lowe, Barnes and Thomas | New Lucasbury, AP | 2021-04-08\n",
      "Programmer, multimedia | Lewis, Gonzalez and Vasquez | Port Cory, AE | 2021-04-08\n",
      "Engineer, broadcasting (operations) | Taylor PLC | Gileston, AA | 2021-04-08\n",
      "Teacher, primary school | Oliver, Jones and Ramirez | Cindyshire, AA | 2021-04-08\n",
      "Python Developer | Rivera and Sons | East Michaelfort, AA | 2021-04-08\n",
      "Manufacturing systems engineer | Garcia PLC | Joybury, AE | 2021-04-08\n",
      "Producer, television/film/video | Johnson, Wells and Kramer | Emmatown, AE | 2021-04-08\n",
      "Scientist, forensic | Gonzalez LLC | Colehaven, AP | 2021-04-08\n",
      "Bonds trader | Morgan, White and Macdonald | Port Coryton, AE | 2021-04-08\n",
      "Editorial assistant | Robinson-Fitzpatrick | Amyborough, AA | 2021-04-08\n",
      "Photographer | Waters, Wilson and Hoover | Reynoldsville, AA | 2021-04-08\n",
      "Retail banker | Hill LLC | Port Billy, AP | 2021-04-08\n",
      "Jewellery designer | Li-Gregory | Adamburgh, AA | 2021-04-08\n",
      "Ophthalmologist | Fisher, Ryan and Coleman | Wilsonmouth, AA | 2021-04-08\n",
      "Back-End Web Developer (Python, Django) | Stewart-Alexander | South Kimberly, AA | 2021-04-08\n",
      "Licensed conveyancer | Abbott and Sons | Benjaminland, AP | 2021-04-08\n",
      "Futures trader | Bryant, Santana and Davenport | Zacharyport, AA | 2021-04-08\n",
      "Counselling psychologist | Smith PLC | Port Devonville, AE | 2021-04-08\n",
      "Insurance underwriter | Patterson-Singh | East Thomas, AE | 2021-04-08\n",
      "Engineer, automotive | Martinez-Berry | New Jeffrey, AP | 2021-04-08\n",
      "Producer, radio | May, Taylor and Fisher | Davidside, AA | 2021-04-08\n",
      "Dispensing optician | Bailey, Owen and Thompson | Jamesville, AA | 2021-04-08\n",
      "Designer, fashion/clothing | Vasquez Ltd | New Kelly, AP | 2021-04-08\n",
      "Chartered loss adjuster | Leblanc LLC | Lake Antonio, AA | 2021-04-08\n",
      "Back-End Web Developer (Python, Django) | Jackson, Ali and Mckee | New Elizabethside, AA | 2021-04-08\n",
      "Forest/woodland manager | Blankenship, Knight and Powell | Millsbury, AE | 2021-04-08\n",
      "Clinical cytogeneticist | Patton, Haynes and Jones | Lloydton, AP | 2021-04-08\n",
      "Print production planner | Wood Inc | Port Jeremy, AA | 2021-04-08\n",
      "Systems developer | Collins Group | New Elizabethtown, AA | 2021-04-08\n",
      "Graphic designer | Flores-Nelson | Charlesstad, AE | 2021-04-08\n",
      "Writer | Mitchell, Jones and Olson | Josephbury, AE | 2021-04-08\n",
      "Field seismologist | Howard Group | Seanfurt, AA | 2021-04-08\n",
      "Chief Strategy Officer | Kramer-Edwards | Williambury, AA | 2021-04-08\n",
      "Air cabin crew | Berry-Houston | South Jorgeside, AP | 2021-04-08\n",
      "Python Programmer (Entry-Level) | Mathews Inc | Robertborough, AP | 2021-04-08\n",
      "Warden/ranger | Riley-Johnson | South Saratown, AP | 2021-04-08\n",
      "Sports therapist | Spencer and Sons | Hullview, AA | 2021-04-08\n",
      "Arts development officer | Camacho-Sanchez | Philipland, AP | 2021-04-08\n",
      "Printmaker | Oliver and Sons | North Patty, AE | 2021-04-08\n",
      "Health and safety adviser | Eaton PLC | North Stephen, AE | 2021-04-08\n",
      "Manufacturing systems engineer | Stanley-Frederick | Stevensland, AP | 2021-04-08\n",
      "Programmer, applications | Bradley LLC | Reyesstad, AE | 2021-04-08\n",
      "Medical physicist | Parker, Goodwin and Zavala | Bellberg, AP | 2021-04-08\n",
      "Media planner | Kim-Miles | North Johnland, AE | 2021-04-08\n",
      "Software Developer (Python) | Moreno-Rodriguez | Martinezburgh, AE | 2021-04-08\n",
      "Surveyor, land/geomatics | Brown-Ortiz | Joshuatown, AE | 2021-04-08\n",
      "Legal executive | Hartman PLC | West Ericstad, AA | 2021-04-08\n",
      "Librarian, academic | Brooks Inc | Tuckertown, AE | 2021-04-08\n",
      "Barrister | Washington-Castillo | Perezton, AE | 2021-04-08\n",
      "Museum/gallery exhibitions officer | Nguyen, Yoder and Petty | Lake Abigail, AE | 2021-04-08\n",
      "Radiographer, diagnostic | Holder LLC | Jacobshire, AP | 2021-04-08\n",
      "Database administrator | Yates-Ferguson | Port Susan, AE | 2021-04-08\n",
      "Furniture designer | Ortega-Lawrence | North Tiffany, AA | 2021-04-08\n",
      "Ship broker | Fuentes, Walls and Castro | Michelleville, AP | 2021-04-08\n"
     ]
    }
   ],
   "source": [
    "for title, company, location, date in zip(titles, companies, locations, posting_dates):\n",
    "    print(f\"{title} | {company} | {location} | {date}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1765a68f-c03c-4ed1-aa9b-458f5a746a41",
   "metadata": {},
   "source": [
    "d. Take the lists that you have created and combine them into a pandas DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6ab72f1a-35e4-4287-ac14-a92a979cb9d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Title                     Company              Location  \\\n",
      "0  Senior Python Developer    Payne, Roberts and Davis       Stewartbury, AA   \n",
      "1          Energy engineer            Vasquez-Davidson  Christopherville, AA   \n",
      "2          Legal executive  Jackson, Chambers and Levy   Port Ericaburgh, AA   \n",
      "3   Fitness centre manager              Savage-Bradley     East Seanview, AP   \n",
      "4          Product manager                 Ramirez Inc   North Jamieview, AP   \n",
      "\n",
      "  Posting Date  \n",
      "0   2021-04-08  \n",
      "1   2021-04-08  \n",
      "2   2021-04-08  \n",
      "3   2021-04-08  \n",
      "4   2021-04-08  \n"
     ]
    }
   ],
   "source": [
    "jobs_df = pd.DataFrame({\n",
    "    'Title': titles,\n",
    "    'Company': companies,\n",
    "    'Location': locations,\n",
    "    'Posting Date': posting_dates\n",
    "})\n",
    "\n",
    "print(jobs_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9b9867-1572-4cdd-a55c-851235cf6c79",
   "metadata": {},
   "source": [
    "2. Next, add a column that contains the url for the \"Apply\" button. Try this in two ways.   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4dc263-13f4-4ac1-890d-f51c199b3595",
   "metadata": {},
   "source": [
    "a. First, use the BeautifulSoup find_all method to extract the urls.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "24e749a4-602a-46cd-ae51-fd2ea0fb0c46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Title                              Apply URL (Extracted)\n",
      "0  Senior Python Developer  https://realpython.github.io/fake-jobs/jobs/se...\n",
      "1          Energy engineer  https://realpython.github.io/fake-jobs/jobs/en...\n",
      "2          Legal executive  https://realpython.github.io/fake-jobs/jobs/le...\n",
      "3   Fitness centre manager  https://realpython.github.io/fake-jobs/jobs/fi...\n",
      "4          Product manager  https://realpython.github.io/fake-jobs/jobs/pr...\n"
     ]
    }
   ],
   "source": [
    "apply_urls = []\n",
    "\n",
    "for card in job_cards:\n",
    "    apply_link = card.find_all('a')[-1]['href'].strip()\n",
    "    apply_urls.append(apply_link)\n",
    "\n",
    "\n",
    "print(jobs_df[['Title', 'Apply URL (Extracted)']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5a84ceea-ffe6-46a0-a04b-d1b1d5570f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://realpython.github.io/fake-jobs/jobs/senior-python-developer-0.html', 'https://realpython.github.io/fake-jobs/jobs/energy-engineer-1.html', 'https://realpython.github.io/fake-jobs/jobs/legal-executive-2.html', 'https://realpython.github.io/fake-jobs/jobs/fitness-centre-manager-3.html', 'https://realpython.github.io/fake-jobs/jobs/product-manager-4.html', 'https://realpython.github.io/fake-jobs/jobs/medical-technical-officer-5.html', 'https://realpython.github.io/fake-jobs/jobs/physiological-scientist-6.html', 'https://realpython.github.io/fake-jobs/jobs/textile-designer-7.html', 'https://realpython.github.io/fake-jobs/jobs/television-floor-manager-8.html', 'https://realpython.github.io/fake-jobs/jobs/waste-management-officer-9.html']\n"
     ]
    }
   ],
   "source": [
    "print(jobs_df['Apply URL (Extracted)'].head(10).to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d89409-7ae3-4727-b7a2-5eb021ebf994",
   "metadata": {},
   "source": [
    "b. Next, get those same urls in a different way. Examine the urls and see if you can spot the pattern of how they are constructed. Then, build the url using the elements you have already extracted. Ensure that the urls that you created match those that you extracted using BeautifulSoup. Warning: You will need to do some string cleaning and prep in constructing the urls this way. For example, look carefully at the urls for the \"Software Engineer (Python)\" job and the \"Scientist, research (maths)\" job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f2c485f0-702c-4f1f-9a16-80f2f907bb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def slugify(title):\n",
    "    slug = title.lower()\n",
    "    slug = re.sub(r'[^\\w\\s-]', '', slug)\n",
    "    slug = re.sub(r'\\s+', '-', slug)\n",
    "    return slug.strip('-')\n",
    "\n",
    "base_url = \"https://realpython.github.io/fake-jobs/jobs/\"\n",
    "manual_urls = [f\"{base_url}{slugify(title)}-{i}.html\" for i, title in enumerate(titles)]\n",
    "\n",
    "jobs_df['Apply URL (Constructed)'] = manual_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0e4b17a8-c1cd-475f-a7a3-c427f06838d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# manual_urls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed2df88-5d80-4810-804d-ee4651213647",
   "metadata": {},
   "source": [
    "3. Finally, we want to get the job description text for each job.  \n",
    "    a. Start by looking at the page for the first job, https://realpython.github.io/fake-jobs/jobs/senior-python-developer-0.html. Using BeautifulSoup, extract the job description paragraph.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9f2d5ef7-4e63-401e-888e-b8d1b74b651a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Professional asset web application environmentally friendly detail-oriented asset. Coordinate educational dashboard agile employ growth opportunity. Company programs CSS explore role. Html educational grit web application. Oversea SCRUM talented support. Web Application fast-growing communities inclusive programs job CSS. Css discussions growth opportunity explore open-minded oversee. Css Python environmentally friendly collaborate inclusive role. Django no experience oversee dashboard environmentally friendly willing to learn programs. Programs open-minded programs asset.\n"
     ]
    }
   ],
   "source": [
    "job_url = \"https://realpython.github.io/fake-jobs/jobs/senior-python-developer-0.html\"\n",
    "\n",
    "response = requests.get(job_url)\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "job_desc_div = soup.find(\"div\", class_=\"content\")\n",
    "job_description = job_desc_div.find(\"p\").get_text(strip=True)\n",
    "\n",
    "print(job_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a2c71b-47ed-431d-8d78-7f56e55e2688",
   "metadata": {},
   "source": [
    "b. We want to be able to do this for all pages. Write a function which takes as input a url and returns the description text on that page. For example, if you input \"https://realpython.github.io/fake-jobs/jobs/television-floor-manager-8.html\" into your function, it should return the string \"At be than always different American address. Former claim chance prevent why measure too. Almost before some military outside baby interview. Face top individual win suddenly. Parent do ten after those scientist. Medical effort assume teacher wall. Significant his himself clearly very. Expert stop area along individual. Three own bank recognize special good along.\".  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f63cc43c-8ddf-4050-a2f3-28e9b1aa69f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_job_description(url):\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    \n",
    "    job_desc_div = soup.find(\"div\", class_=\"content\")\n",
    "    \n",
    "    job_description = job_desc_div.find(\"p\").get_text(strip=True)\n",
    "    \n",
    "    return job_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a91cd49c-75c7-495b-b382-ccc7800c3d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At be than always different American address. Former claim chance prevent why measure too. Almost before some military outside baby interview. Face top individual win suddenly. Parent do ten after those scientist. Medical effort assume teacher wall. Significant his himself clearly very. Expert stop area along individual. Three own bank recognize special good along.\n"
     ]
    }
   ],
   "source": [
    "url = \"https://realpython.github.io/fake-jobs/jobs/television-floor-manager-8.html\"\n",
    "description = get_job_description(url)\n",
    "\n",
    "print(description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2f582470-54b4-4ea1-b3f5-ed2eab23de34",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_df[\"Description\"] = jobs_df[\"Apply URL (Extracted)\"].apply(get_job_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2d48678a-a801-41e8-a9e3-539ad5e8bb5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>Posting Date</th>\n",
       "      <th>Apply URL (Extracted)</th>\n",
       "      <th>Apply URL (Constructed)</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Python Developer</td>\n",
       "      <td>Payne, Roberts and Davis</td>\n",
       "      <td>Stewartbury, AA</td>\n",
       "      <td>2021-04-08</td>\n",
       "      <td>https://realpython.github.io/fake-jobs/jobs/se...</td>\n",
       "      <td>https://realpython.github.io/fake-jobs/jobs/se...</td>\n",
       "      <td>Professional asset web application environment...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Energy engineer</td>\n",
       "      <td>Vasquez-Davidson</td>\n",
       "      <td>Christopherville, AA</td>\n",
       "      <td>2021-04-08</td>\n",
       "      <td>https://realpython.github.io/fake-jobs/jobs/en...</td>\n",
       "      <td>https://realpython.github.io/fake-jobs/jobs/en...</td>\n",
       "      <td>Party prevent live. Quickly candidate change a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Legal executive</td>\n",
       "      <td>Jackson, Chambers and Levy</td>\n",
       "      <td>Port Ericaburgh, AA</td>\n",
       "      <td>2021-04-08</td>\n",
       "      <td>https://realpython.github.io/fake-jobs/jobs/le...</td>\n",
       "      <td>https://realpython.github.io/fake-jobs/jobs/le...</td>\n",
       "      <td>Administration even relate head color. Staff b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fitness centre manager</td>\n",
       "      <td>Savage-Bradley</td>\n",
       "      <td>East Seanview, AP</td>\n",
       "      <td>2021-04-08</td>\n",
       "      <td>https://realpython.github.io/fake-jobs/jobs/fi...</td>\n",
       "      <td>https://realpython.github.io/fake-jobs/jobs/fi...</td>\n",
       "      <td>Tv program actually race tonight themselves tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Product manager</td>\n",
       "      <td>Ramirez Inc</td>\n",
       "      <td>North Jamieview, AP</td>\n",
       "      <td>2021-04-08</td>\n",
       "      <td>https://realpython.github.io/fake-jobs/jobs/pr...</td>\n",
       "      <td>https://realpython.github.io/fake-jobs/jobs/pr...</td>\n",
       "      <td>Traditional page a although for study anyone. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Museum/gallery exhibitions officer</td>\n",
       "      <td>Nguyen, Yoder and Petty</td>\n",
       "      <td>Lake Abigail, AE</td>\n",
       "      <td>2021-04-08</td>\n",
       "      <td>https://realpython.github.io/fake-jobs/jobs/mu...</td>\n",
       "      <td>https://realpython.github.io/fake-jobs/jobs/mu...</td>\n",
       "      <td>Paper age physical current note. There reality...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Radiographer, diagnostic</td>\n",
       "      <td>Holder LLC</td>\n",
       "      <td>Jacobshire, AP</td>\n",
       "      <td>2021-04-08</td>\n",
       "      <td>https://realpython.github.io/fake-jobs/jobs/ra...</td>\n",
       "      <td>https://realpython.github.io/fake-jobs/jobs/ra...</td>\n",
       "      <td>Able such right culture. Wrong pick structure ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Database administrator</td>\n",
       "      <td>Yates-Ferguson</td>\n",
       "      <td>Port Susan, AE</td>\n",
       "      <td>2021-04-08</td>\n",
       "      <td>https://realpython.github.io/fake-jobs/jobs/da...</td>\n",
       "      <td>https://realpython.github.io/fake-jobs/jobs/da...</td>\n",
       "      <td>Create day party decade high clear. Past trade...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Furniture designer</td>\n",
       "      <td>Ortega-Lawrence</td>\n",
       "      <td>North Tiffany, AA</td>\n",
       "      <td>2021-04-08</td>\n",
       "      <td>https://realpython.github.io/fake-jobs/jobs/fu...</td>\n",
       "      <td>https://realpython.github.io/fake-jobs/jobs/fu...</td>\n",
       "      <td>Pressure under rock next week. Recognize so re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Ship broker</td>\n",
       "      <td>Fuentes, Walls and Castro</td>\n",
       "      <td>Michelleville, AP</td>\n",
       "      <td>2021-04-08</td>\n",
       "      <td>https://realpython.github.io/fake-jobs/jobs/sh...</td>\n",
       "      <td>https://realpython.github.io/fake-jobs/jobs/sh...</td>\n",
       "      <td>Management common popular project only. Must s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Title                     Company  \\\n",
       "0              Senior Python Developer    Payne, Roberts and Davis   \n",
       "1                      Energy engineer            Vasquez-Davidson   \n",
       "2                      Legal executive  Jackson, Chambers and Levy   \n",
       "3               Fitness centre manager              Savage-Bradley   \n",
       "4                      Product manager                 Ramirez Inc   \n",
       "..                                 ...                         ...   \n",
       "95  Museum/gallery exhibitions officer     Nguyen, Yoder and Petty   \n",
       "96            Radiographer, diagnostic                  Holder LLC   \n",
       "97              Database administrator              Yates-Ferguson   \n",
       "98                  Furniture designer             Ortega-Lawrence   \n",
       "99                         Ship broker   Fuentes, Walls and Castro   \n",
       "\n",
       "                Location Posting Date  \\\n",
       "0        Stewartbury, AA   2021-04-08   \n",
       "1   Christopherville, AA   2021-04-08   \n",
       "2    Port Ericaburgh, AA   2021-04-08   \n",
       "3      East Seanview, AP   2021-04-08   \n",
       "4    North Jamieview, AP   2021-04-08   \n",
       "..                   ...          ...   \n",
       "95      Lake Abigail, AE   2021-04-08   \n",
       "96        Jacobshire, AP   2021-04-08   \n",
       "97        Port Susan, AE   2021-04-08   \n",
       "98     North Tiffany, AA   2021-04-08   \n",
       "99     Michelleville, AP   2021-04-08   \n",
       "\n",
       "                                Apply URL (Extracted)  \\\n",
       "0   https://realpython.github.io/fake-jobs/jobs/se...   \n",
       "1   https://realpython.github.io/fake-jobs/jobs/en...   \n",
       "2   https://realpython.github.io/fake-jobs/jobs/le...   \n",
       "3   https://realpython.github.io/fake-jobs/jobs/fi...   \n",
       "4   https://realpython.github.io/fake-jobs/jobs/pr...   \n",
       "..                                                ...   \n",
       "95  https://realpython.github.io/fake-jobs/jobs/mu...   \n",
       "96  https://realpython.github.io/fake-jobs/jobs/ra...   \n",
       "97  https://realpython.github.io/fake-jobs/jobs/da...   \n",
       "98  https://realpython.github.io/fake-jobs/jobs/fu...   \n",
       "99  https://realpython.github.io/fake-jobs/jobs/sh...   \n",
       "\n",
       "                              Apply URL (Constructed)  \\\n",
       "0   https://realpython.github.io/fake-jobs/jobs/se...   \n",
       "1   https://realpython.github.io/fake-jobs/jobs/en...   \n",
       "2   https://realpython.github.io/fake-jobs/jobs/le...   \n",
       "3   https://realpython.github.io/fake-jobs/jobs/fi...   \n",
       "4   https://realpython.github.io/fake-jobs/jobs/pr...   \n",
       "..                                                ...   \n",
       "95  https://realpython.github.io/fake-jobs/jobs/mu...   \n",
       "96  https://realpython.github.io/fake-jobs/jobs/ra...   \n",
       "97  https://realpython.github.io/fake-jobs/jobs/da...   \n",
       "98  https://realpython.github.io/fake-jobs/jobs/fu...   \n",
       "99  https://realpython.github.io/fake-jobs/jobs/sh...   \n",
       "\n",
       "                                          Description  \n",
       "0   Professional asset web application environment...  \n",
       "1   Party prevent live. Quickly candidate change a...  \n",
       "2   Administration even relate head color. Staff b...  \n",
       "3   Tv program actually race tonight themselves tr...  \n",
       "4   Traditional page a although for study anyone. ...  \n",
       "..                                                ...  \n",
       "95  Paper age physical current note. There reality...  \n",
       "96  Able such right culture. Wrong pick structure ...  \n",
       "97  Create day party decade high clear. Past trade...  \n",
       "98  Pressure under rock next week. Recognize so re...  \n",
       "99  Management common popular project only. Must s...  \n",
       "\n",
       "[100 rows x 7 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
